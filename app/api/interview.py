import base64
import json
import os

from agents import Runner
from fastapi import APIRouter, Query, WebSocket, WebSocketDisconnect

from app.agents.interviewee_agent import create_interviewee_agent
from app.agents.prompts.utils import load_prompts
from app.model.stt import STT
from app.model.tts import TTS
from app.model.ttt import TTT

# –í—Ä–µ–º–µ–Ω–Ω–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è –∞—É–¥–∏–æ—Ñ–∞–π–ª–æ–≤
TEMP_DIR = "/tmp/ai-interview-temp"
os.makedirs(TEMP_DIR, exist_ok=True)

router = APIRouter()

# –ú–æ–¥–µ–ª–∏ –∏ –≤—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ –∫–ª–∞—Å—Å—ã
ttt = TTT()
stt = STT()
tts = TTS()

# –ü—Ä–æ–º–ø—Ç—ã
prompts = load_prompts("persona_system_prompt.yaml")


@router.websocket("/ws/interview")
async def websocket_interview(
    ws: WebSocket,
    persona: str = Query("Junior Python Developer"),
    skill: str = Query("Python programming"),
):
    await ws.accept()

    # –°–æ–∑–¥–∞—ë–º —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç –∏ –∞–≥–µ–Ω—Ç–∞
    system_prompt = prompts["persona_system_prompt"].format(
        persona=persona, skill=skill
    )
    interviewee = create_interviewee_agent(system_prompt)
    agent = interviewee.get_agent()

    try:
        while True:
            data = await ws.receive_text()
            json_data = json.loads(data)

            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö: —Ç–µ–∫—Å—Ç –∏–ª–∏ –∞—É–¥–∏–æ
            if json_data["type"] == "text":
                user_input = json_data.get("message", "")
                is_audio = False
            elif json_data["type"] == "audio":
                audio_bytes = base64.b64decode(json_data["audio"])
                temp_audio_path = os.path.join(TEMP_DIR, "temp_audio.wav")
                with open(temp_audio_path, "wb") as f:
                    f.write(audio_bytes)
                user_input = stt.transcribe_from_path(temp_audio_path)
                is_audio = True
            else:
                continue  # –ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ç–∏–ø

            # –î–æ–±–∞–≤–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –≤ –∏—Å—Ç–æ—Ä–∏—é
            interviewee.append_to_history("user", user_input)

            # –ü–æ–ª—É—á–∞–µ–º –æ—Ç–≤–µ—Ç –æ—Ç –∞–≥–µ–Ω—Ç–∞ —Å —É—á—ë—Ç–æ–º –≤—Å–µ–π –∏—Å—Ç–æ—Ä–∏–∏
            response = await Runner.run(
                agent, user_input, context={"messages": interviewee.get_messages()}
            )
            agent_text = response.final_output

            # –î–æ–±–∞–≤–ª—è–µ–º –æ—Ç–≤–µ—Ç –∞–≥–µ–Ω—Ç–∞ –≤ –∏—Å—Ç–æ—Ä–∏—é
            interviewee.append_to_history("assistant", agent_text)

            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –æ—Ç–≤–µ—Ç –æ–±—Ä–∞—Ç–Ω–æ –∫–ª–∏–µ–Ω—Ç—É
            if is_audio:
                tts_response = tts.generate_speech(
                    agent_text, tone=prompts["persona_voice_tone_prompt"]
                )
                agent_audio = base64.b64encode(tts_response.content).decode("utf-8")

                await ws.send_json(
                    {
                        "type": "voice",
                        "content": agent_text,
                        "user_text": user_input,
                        "audio": agent_audio,
                    }
                )
            else:
                await ws.send_json({"type": "text", "content": agent_text})

    except WebSocketDisconnect:
        print("üîå Client disconnected")
